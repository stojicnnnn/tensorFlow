import rerun as rr
import numpy as np
from scipy.spatial.transform import Rotation # For RPY conversion (pip install scipy)
import industry_picking.perception.pose_esimator as pest
import cv2
import time
import pyrealsense2 as rs
import open3d as o3d
from industry_picking.cameras.camera import RealSense
import industry_picking.utils.helper_functions as help



if __name__ == "__main__":
    
    cam_fx = 613.256
    cam_fy = 612.151
    cam_cx = 328.348
    cam_cy = 235.462
    example_camera_K = np.array([
          [cam_fx, 0, cam_cx],
          [0, cam_fy, cam_cy],
          [0, 0,  1]
      ])
    
    
    #cam = RealSense(width=1280,height=720)
    #cam.connect()
    #example_camera_K, _= cam.getIntrinsics()
    #img , depth = cam.captureImage()
    #help.save_image_to_file(image_data=img , file_path=r"C:\Users\Nikola\OneDrive\Desktop\zividSlike\data\imgNova.png")
    #help.save_image_to_file(image_data=depth , file_path=r"C:\Users\Nikola\OneDrive\Desktop\zividSlike\data\depthNova.png")

    path_to_raw_rgb_for_sam = r"industry_picking\data\imgNova.png" # Original RGB for SAM
    path_to_raw_depth = r"industry_picking\data\depthNova.png" # Original Depth
    
    # --- DEBUG: Print depth image dtype and min/max ---
    depth_image_raw = cv2.imread(path_to_raw_depth, cv2.IMREAD_UNCHANGED)
    if depth_image_raw is not None:
        print("[DEBUG] Depth image dtype:", depth_image_raw.dtype)
        print("[DEBUG] Depth image min/max:", np.min(depth_image_raw), np.max(depth_image_raw))
    else:
        print("[DEBUG] Failed to load depth image for debug print.")
    path_to_reference_model = r"industry_picking\data\ScaledStator.pcd"# Our best sample of an object we are picking

    example_camera_T_world_cam = np.identity(4) #iz handeye kalibracije


    generated_robot_waypoints = pest.generate_waypoints(
            rgb_image_sam_path=path_to_raw_rgb_for_sam,
            depth_image_path=path_to_raw_depth,
            camera_intrinsics_k=example_camera_K, # Use the K matrix for your specific camera and depth resolution
            camera_extrinsics=example_camera_T_world_cam,
            reference_object_path=path_to_reference_model,
            sam_server_url=  "http://192.168.2.168:8090/sam2", # Your SAM server
            sam_query="Segment the circular grey metallic caps,1 instance at a time, in order", # Your SAM query
            voxel_size_registration=0.001, #0.0001, # Adjust as needed
            depth_scale_to_meters=1000.0, # If depth values are in mm
            rerun_visualization=True,
            masks_output_dir= None,
            masks_input_dir=r"industry_picking\data\mask", # Where to load from
            apply_mask=True
    )
    
    if generated_robot_waypoints:
        print(f"\n--- Generated {len(generated_robot_waypoints)} raw waypoints. Now filtering duplicates... ---")

        

        # Define how close two waypoints can be before being called a duplicate.
        MINIMUM_DISTANCE_BETWEEN_OBJECTS = 0.01 # 2 centimeters

        final_waypoints = pest.filter_duplicate_waypoints(
            generated_robot_waypoints,
            min_distance=MINIMUM_DISTANCE_BETWEEN_OBJECTS
        )

    if final_waypoints:
            print("\nVisualizing final waypoints and path in Rerun under 'world/final_waypoints'...")

            # First, log the connecting line strip for the clean path
            final_path_positions = [wp[:3] for wp in final_waypoints]
            
            # Then, log each final waypoint as a coordinate system pose
            for idx, wp in enumerate(final_waypoints):
                translation = wp[:3]
                # The waypoint stores RPY angles; we need to convert them back to a rotation matrix for Rerun
                rotation_matrix = Rotation.from_euler('xyz', wp[3:], degrees=False).as_matrix()
                
                rr.log(
                    f"world/final_waypoints/{idx}",
                    rr.Transform3D(
                        translation=translation,
                        mat3x3=rotation_matrix,
                        axis_length=0.05 
                    )
                )
                # If using the workaround for older SDKs:
                # axis_length = 0.05
                # rr.log(f"world/final_waypoints/{idx}/axes", rr.Arrows3D(...))

    else:
        print("No waypoints were generated by the function.")
    time.sleep(60)
    