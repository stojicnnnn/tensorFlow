import rerun as rr
import numpy as np
from scipy.spatial.transform import Rotation
import zivid.experimental
import zivid.experimental.calibration # For RPY conversion (pip install scipy)
import industry_picking.perception.pose_esimator as pest
import cv2
import time
import zivid
import os
from pathlib import Path 
import matplotlib.pyplot as plt
import open3d as o3d
from zivid import PointCloud
from typing import List, Optional, Tuple
import pyvista as pv
from industry_picking.cameras.camera import RealSense
from industry_picking.utils import helper_functions as help
from industry_picking.robots.xarm import Xarm
from scipy.spatial.transform import Rotation as R

            
if __name__ == "__main__":
    
    arm = Xarm("192.168.1.184")
    arm.connect()
    cam = RealSense(width=1280,height=720)
    cam.connect()
    example_camera_K, _= cam.getIntrinsics()
    img , depth = cam.captureImage()
    
    # We save depth and rgb images so we can reuse them later if the camera is not present #
    help.save_image_to_file(image_data=img , file_path=r"C:\Users\Nikola\OneDrive\Desktop\zividSlike\data\imgNova.png")
    help.save_image_to_file(image_data=depth , file_path=r"C:\Users\Nikola\OneDrive\Desktop\zividSlike\data\depthNova.png")
    
    path_to_raw_rgb_for_sam =  r"C:\Users\Nikola\OneDrive\Desktop\zividSlike\data\imgNova.png" # Original RGB for SAM
    path_to_raw_depth = r"C:\Users\Nikola\OneDrive\Desktop\zividSlike\data\depthNova.png" # Original Depth
    path_to_reference_model = r"C:\Users\Nikola\OneDrive\Desktop\zividSlike\2xmanjiCC.ply" # Our best sample of an object we are picking
    masks_path = r"C:\Users\Nikola\OneDrive\Desktop\zividSlike\uglovi\3maske"
    
    # Camera extrinsics which we got from hand eye calibration #
    example_camera_T_world_cam =  [[ 0.00705456,  0.99996948, -0.00335601,  0.43244419],
            [ 0.99984465, -0.00710781, -0.01612942, -0.03129219],
            [-0.01615278, -0.0032417 , -0.99986428,  0.39502932],
            [ 0.        ,  0.        ,  0.        ,  1.        ]] 


    generated_robot_waypoints = pest.generate_waypoints(
            rgb_image_sam_path=path_to_raw_rgb_for_sam,
            depth_image_path=path_to_raw_depth,
            camera_intrinsics_k=example_camera_K, # Use the K matrix for your specific camera and depth resolution
            camera_extrinsics=example_camera_T_world_cam,
            reference_object_path=path_to_reference_model,
            sam_server_url= "http://192.168.2.168:8090/sam2", # Your SAM server
            sam_query="Segment the circular grey metallic caps,1 instance at a time, in order", # Your SAM query
            voxel_size_registration=0.001, #0.001, # Adjust as needed
            depth_scale_to_meters=1000.0, # If depth values are in mm
            rerun_visualization=True,
            masks_output_dir= None,
            masks_input_dir=masks_path, # Where to load from
            apply_mask=True
    )
    if generated_robot_waypoints:
        print(f"\n--- Generated {len(generated_robot_waypoints)} raw waypoints. Now filtering duplicates... ---")
         # Define how close two waypoints can be before being called a duplicate.
        MINIMUM_DISTANCE_BETWEEN_OBJECTS = 0.1 # 2 centimeters

        final_waypoints = pest.filter_duplicate_waypoints(
            generated_robot_waypoints,
            min_distance=MINIMUM_DISTANCE_BETWEEN_OBJECTS
        )
        

    if final_waypoints:
            print("\nVisualizing final waypoints and path in Rerun under 'world/final_waypoints'...")

            # First, log the connecting line strip for the clean path
            final_path_positions = [wp[:3] for wp in final_waypoints]
            
            # Then, log each final waypoint as a coordinate system pose
            for idx, wp in enumerate(final_waypoints):
               # Extract translation (xyz) from the 4x4 matrix
                translation = wp[:3, 3]  # Last column (rows 0-2, column 3)
                
                # Extract rotation matrix (3x3) from the 4x4 matrix
                rotation_matrix = wp[:3, :3]  # Top-left 3x3 block
                
                rr.log(
                    f"world/final_waypoints/{idx}",
                    rr.Transform3D(
                        translation=translation,
                        mat3x3=rotation_matrix,
                        axis_length=0.05 
                    )
                )
            arm.pick(pose=wp)
        
            
    else:
        print("No waypoints were generated by the function.")
    time.sleep(60)
    